{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rolling Window Sizes - Experiments Results Analysis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a result of the previous experiment, LSTM was the best performer model with the following parameters:\n",
    "- Sensor: Gyroscope.\n",
    "- Location: Feet.\n",
    "- Features: Frequency Domain Features.\n",
    "- Leg: Both legs.\n",
    "\n",
    "After that, I applied a Grid-Search Cross Validation for Hyperparameters Tuning\n",
    "and the following hyperparameter were the best:\n",
    "- Epochs: 50\n",
    "- Batches: 64\n",
    "- Number of hidden layers: 3\n",
    "- Hidden layer activation function: Relu\n",
    "- Output layer activation function: Softmax\n",
    "- Optimizer: Adam\n",
    "- Dropout Rate: 0.6\n",
    "- Kernel Initializer: Uniform\n",
    "\n",
    "For each window size, I choosed 0.1 of the window size as an overlapping step.\n",
    "\n",
    "For each window size, I did a Leave-one-patient-out Cross-validation to see how\n",
    "the impact of this change would affect the model performance on every single patient."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['window', 'step', 'test_patient', 'train_shape', 'test_shape',\n       'train_lable_count', 'test_label_count', 'accuracy', 'f1_score',\n       'precision', 'recall', 'conf_matrix', 'clf_report', 'loss'],\n      dtype='object')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('windows_results.csv', sep=',')\n",
    "df.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Average (F1, Precision, Recall, Accuracy) For Each Window Size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "             f1_score  precision    recall  accuracy      loss\nwindow step                                                   \n200    20    0.768665   0.772391  0.772391  0.772391  0.531842\n300    30    0.766977   0.773462  0.773462  0.773462  0.497387\n400    40    0.801255   0.818742  0.818742  0.818742  0.478788\n500    50    0.776298   0.782341  0.782341  0.782341  0.466432\n600    60    0.799161   0.803789  0.803789  0.803789  0.421888\n700    70    0.800882   0.805657  0.805657  0.805657  0.412159\n800    80    0.803910   0.816482  0.816482  0.816482  0.396200\n900    90    0.832466   0.830304  0.830304  0.830304  0.400475",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>f1_score</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>accuracy</th>\n      <th>loss</th>\n    </tr>\n    <tr>\n      <th>window</th>\n      <th>step</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>200</th>\n      <th>20</th>\n      <td>0.768665</td>\n      <td>0.772391</td>\n      <td>0.772391</td>\n      <td>0.772391</td>\n      <td>0.531842</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <th>30</th>\n      <td>0.766977</td>\n      <td>0.773462</td>\n      <td>0.773462</td>\n      <td>0.773462</td>\n      <td>0.497387</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <th>40</th>\n      <td>0.801255</td>\n      <td>0.818742</td>\n      <td>0.818742</td>\n      <td>0.818742</td>\n      <td>0.478788</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <th>50</th>\n      <td>0.776298</td>\n      <td>0.782341</td>\n      <td>0.782341</td>\n      <td>0.782341</td>\n      <td>0.466432</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <th>60</th>\n      <td>0.799161</td>\n      <td>0.803789</td>\n      <td>0.803789</td>\n      <td>0.803789</td>\n      <td>0.421888</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <th>70</th>\n      <td>0.800882</td>\n      <td>0.805657</td>\n      <td>0.805657</td>\n      <td>0.805657</td>\n      <td>0.412159</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <th>80</th>\n      <td>0.803910</td>\n      <td>0.816482</td>\n      <td>0.816482</td>\n      <td>0.816482</td>\n      <td>0.396200</td>\n    </tr>\n    <tr>\n      <th>900</th>\n      <th>90</th>\n      <td>0.832466</td>\n      <td>0.830304</td>\n      <td>0.830304</td>\n      <td>0.830304</td>\n      <td>0.400475</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = df.groupby(['window', 'step'])[['f1_score', 'precision' , 'recall', 'accuracy', 'loss']].mean()\n",
    "results_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The results of Leave-one-out Cross Validation using the LSTM model using the best window size of (900)\n",
    "### Results are sorted by F1-Score in a descending order"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "     window  step test_patient train_shape  test_shape  \\\n119     900    90         P231  (7842, 25)   (302, 25)   \n127     900    90         P940  (7205, 25)   (939, 25)   \n117     900    90          G09  (7901, 25)   (243, 25)   \n114     900    90          G06  (7956, 25)   (188, 25)   \n120     900    90         P351  (7024, 25)  (1120, 25)   \n123     900    90         P623  (7935, 25)   (209, 25)   \n122     900    90         P551  (7758, 25)   (386, 25)   \n125     900    90         P812  (6674, 25)  (1470, 25)   \n121     900    90         P379  (7729, 25)   (415, 25)   \n126     900    90         P876  (7895, 25)   (249, 25)   \n118     900    90          G11  (7993, 25)   (151, 25)   \n124     900    90         P645  (7811, 25)   (333, 25)   \n115     900    90          G07  (7796, 25)   (348, 25)   \n113     900    90          G05  (7953, 25)   (191, 25)   \n116     900    90          G08  (6856, 25)  (1288, 25)   \n112     900    90          G04  (7832, 25)   (312, 25)   \n\n          train_lable_count       test_label_count  accuracy  f1_score  \\\n119  {0.0: 5267, 1.0: 2575}             {0.0: 302}  0.989967  0.990625   \n127  {0.0: 4630, 1.0: 2575}             {0.0: 939}  0.982906  0.980208   \n117  {0.0: 5326, 1.0: 2575}             {0.0: 243}  0.954167  0.950521   \n114  {0.0: 5449, 1.0: 2507}    {0.0: 120, 1.0: 68}  0.935135  0.936221   \n120  {0.0: 4449, 1.0: 2575}            {0.0: 1120}  0.919427  0.921875   \n123  {0.0: 5360, 1.0: 2575}             {0.0: 209}  0.883495  0.906250   \n122  {0.0: 5523, 1.0: 2235}    {1.0: 340, 0.0: 46}  0.906005  0.905961   \n125  {0.0: 4363, 1.0: 2311}  {0.0: 1206, 1.0: 264}  0.892297  0.892548   \n121  {0.0: 5297, 1.0: 2432}   {0.0: 272, 1.0: 143}  0.873786  0.881059   \n126  {0.0: 5320, 1.0: 2575}             {0.0: 249}  0.878049  0.880642   \n118  {0.0: 5447, 1.0: 2546}    {0.0: 122, 1.0: 29}  0.804054  0.848958   \n124  {0.0: 5236, 1.0: 2575}             {0.0: 333}  0.818182  0.843750   \n115  {0.0: 5514, 1.0: 2282}    {1.0: 293, 0.0: 55}  0.878261  0.817500   \n113  {0.0: 5378, 1.0: 2575}             {0.0: 191}  0.696809  0.698611   \n116  {0.0: 5484, 1.0: 1372}   {1.0: 1203, 0.0: 85}  0.445136  0.443155   \n112  {0.0: 5492, 1.0: 2340}    {1.0: 235, 0.0: 77}  0.427184  0.421580   \n\n     precision    recall                  conf_matrix  \\\n119   0.989967  0.989967      [[296   3]\\n [  0   0]]   \n127   0.982906  0.982906      [[920  16]\\n [  0   0]]   \n117   0.954167  0.954167      [[229  11]\\n [  0   0]]   \n114   0.935135  0.935135      [[113   4]\\n [  8  60]]   \n120   0.919427  0.919427  [[1027   90]\\n [   0    0]]   \n123   0.883495  0.883495      [[182  24]\\n [  0   0]]   \n122   0.906005  0.906005      [[  9  35]\\n [  1 338]]   \n125   0.892297  0.892297  [[1090  113]\\n [  45  219]]   \n121   0.873786  0.873786      [[249  20]\\n [ 32 111]]   \n126   0.878049  0.878049      [[216  30]\\n [  0   0]]   \n118   0.804054  0.804054          [[90 29]\\n [ 0 29]]   \n124   0.818182  0.818182      [[270  60]\\n [  0   0]]   \n115   0.878261  0.878261      [[ 12  40]\\n [  2 291]]   \n113   0.696809  0.696809      [[131  57]\\n [  0   0]]   \n116   0.445136  0.445136      [[ 62  21]\\n [692 510]]   \n112   0.427184  0.427184      [[  8  66]\\n [111 124]]   \n\n                                            clf_report      loss  \n119  {'0': {'precision': 1.0, 'recall': 0.989966555...  0.018532  \n127  {'0': {'precision': 1.0, 'recall': 0.982905982...  0.032510  \n117  {'0': {'precision': 1.0, 'recall': 0.954166666...  0.079220  \n114  {'0': {'precision': 0.9338842975206612, 'recal...  0.283994  \n120  {'0': {'precision': 1.0, 'recall': 0.919427036...  0.129470  \n123  {'0': {'precision': 1.0, 'recall': 0.883495145...  0.190756  \n122  {'0': {'precision': 0.9, 'recall': 0.204545454...  0.371937  \n125  {'0': {'precision': 0.960352422907489, 'recall...  0.271780  \n121  {'0': {'precision': 0.8861209964412812, 'recal...  0.649162  \n126  {'0': {'precision': 1.0, 'recall': 0.878048780...  0.199090  \n118  {'0': {'precision': 1.0, 'recall': 0.756302521...  0.351790  \n124  {'0': {'precision': 1.0, 'recall': 0.818181818...  0.318321  \n115  {'0': {'precision': 0.8571428571428571, 'recal...  0.411816  \n113  {'0': {'precision': 1.0, 'recall': 0.696808510...  0.456545  \n116  {'0': {'precision': 0.08222811671087533, 'reca...  1.289882  \n112  {'0': {'precision': 0.06722689075630252, 'reca...  1.352790  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window</th>\n      <th>step</th>\n      <th>test_patient</th>\n      <th>train_shape</th>\n      <th>test_shape</th>\n      <th>train_lable_count</th>\n      <th>test_label_count</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>conf_matrix</th>\n      <th>clf_report</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>119</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P231</td>\n      <td>(7842, 25)</td>\n      <td>(302, 25)</td>\n      <td>{0.0: 5267, 1.0: 2575}</td>\n      <td>{0.0: 302}</td>\n      <td>0.989967</td>\n      <td>0.990625</td>\n      <td>0.989967</td>\n      <td>0.989967</td>\n      <td>[[296   3]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.989966555...</td>\n      <td>0.018532</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P940</td>\n      <td>(7205, 25)</td>\n      <td>(939, 25)</td>\n      <td>{0.0: 4630, 1.0: 2575}</td>\n      <td>{0.0: 939}</td>\n      <td>0.982906</td>\n      <td>0.980208</td>\n      <td>0.982906</td>\n      <td>0.982906</td>\n      <td>[[920  16]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.982905982...</td>\n      <td>0.032510</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G09</td>\n      <td>(7901, 25)</td>\n      <td>(243, 25)</td>\n      <td>{0.0: 5326, 1.0: 2575}</td>\n      <td>{0.0: 243}</td>\n      <td>0.954167</td>\n      <td>0.950521</td>\n      <td>0.954167</td>\n      <td>0.954167</td>\n      <td>[[229  11]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.954166666...</td>\n      <td>0.079220</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G06</td>\n      <td>(7956, 25)</td>\n      <td>(188, 25)</td>\n      <td>{0.0: 5449, 1.0: 2507}</td>\n      <td>{0.0: 120, 1.0: 68}</td>\n      <td>0.935135</td>\n      <td>0.936221</td>\n      <td>0.935135</td>\n      <td>0.935135</td>\n      <td>[[113   4]\\n [  8  60]]</td>\n      <td>{'0': {'precision': 0.9338842975206612, 'recal...</td>\n      <td>0.283994</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P351</td>\n      <td>(7024, 25)</td>\n      <td>(1120, 25)</td>\n      <td>{0.0: 4449, 1.0: 2575}</td>\n      <td>{0.0: 1120}</td>\n      <td>0.919427</td>\n      <td>0.921875</td>\n      <td>0.919427</td>\n      <td>0.919427</td>\n      <td>[[1027   90]\\n [   0    0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.919427036...</td>\n      <td>0.129470</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P623</td>\n      <td>(7935, 25)</td>\n      <td>(209, 25)</td>\n      <td>{0.0: 5360, 1.0: 2575}</td>\n      <td>{0.0: 209}</td>\n      <td>0.883495</td>\n      <td>0.906250</td>\n      <td>0.883495</td>\n      <td>0.883495</td>\n      <td>[[182  24]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.883495145...</td>\n      <td>0.190756</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P551</td>\n      <td>(7758, 25)</td>\n      <td>(386, 25)</td>\n      <td>{0.0: 5523, 1.0: 2235}</td>\n      <td>{1.0: 340, 0.0: 46}</td>\n      <td>0.906005</td>\n      <td>0.905961</td>\n      <td>0.906005</td>\n      <td>0.906005</td>\n      <td>[[  9  35]\\n [  1 338]]</td>\n      <td>{'0': {'precision': 0.9, 'recall': 0.204545454...</td>\n      <td>0.371937</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P812</td>\n      <td>(6674, 25)</td>\n      <td>(1470, 25)</td>\n      <td>{0.0: 4363, 1.0: 2311}</td>\n      <td>{0.0: 1206, 1.0: 264}</td>\n      <td>0.892297</td>\n      <td>0.892548</td>\n      <td>0.892297</td>\n      <td>0.892297</td>\n      <td>[[1090  113]\\n [  45  219]]</td>\n      <td>{'0': {'precision': 0.960352422907489, 'recall...</td>\n      <td>0.271780</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P379</td>\n      <td>(7729, 25)</td>\n      <td>(415, 25)</td>\n      <td>{0.0: 5297, 1.0: 2432}</td>\n      <td>{0.0: 272, 1.0: 143}</td>\n      <td>0.873786</td>\n      <td>0.881059</td>\n      <td>0.873786</td>\n      <td>0.873786</td>\n      <td>[[249  20]\\n [ 32 111]]</td>\n      <td>{'0': {'precision': 0.8861209964412812, 'recal...</td>\n      <td>0.649162</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P876</td>\n      <td>(7895, 25)</td>\n      <td>(249, 25)</td>\n      <td>{0.0: 5320, 1.0: 2575}</td>\n      <td>{0.0: 249}</td>\n      <td>0.878049</td>\n      <td>0.880642</td>\n      <td>0.878049</td>\n      <td>0.878049</td>\n      <td>[[216  30]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.878048780...</td>\n      <td>0.199090</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G11</td>\n      <td>(7993, 25)</td>\n      <td>(151, 25)</td>\n      <td>{0.0: 5447, 1.0: 2546}</td>\n      <td>{0.0: 122, 1.0: 29}</td>\n      <td>0.804054</td>\n      <td>0.848958</td>\n      <td>0.804054</td>\n      <td>0.804054</td>\n      <td>[[90 29]\\n [ 0 29]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.756302521...</td>\n      <td>0.351790</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P645</td>\n      <td>(7811, 25)</td>\n      <td>(333, 25)</td>\n      <td>{0.0: 5236, 1.0: 2575}</td>\n      <td>{0.0: 333}</td>\n      <td>0.818182</td>\n      <td>0.843750</td>\n      <td>0.818182</td>\n      <td>0.818182</td>\n      <td>[[270  60]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.818181818...</td>\n      <td>0.318321</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G07</td>\n      <td>(7796, 25)</td>\n      <td>(348, 25)</td>\n      <td>{0.0: 5514, 1.0: 2282}</td>\n      <td>{1.0: 293, 0.0: 55}</td>\n      <td>0.878261</td>\n      <td>0.817500</td>\n      <td>0.878261</td>\n      <td>0.878261</td>\n      <td>[[ 12  40]\\n [  2 291]]</td>\n      <td>{'0': {'precision': 0.8571428571428571, 'recal...</td>\n      <td>0.411816</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G05</td>\n      <td>(7953, 25)</td>\n      <td>(191, 25)</td>\n      <td>{0.0: 5378, 1.0: 2575}</td>\n      <td>{0.0: 191}</td>\n      <td>0.696809</td>\n      <td>0.698611</td>\n      <td>0.696809</td>\n      <td>0.696809</td>\n      <td>[[131  57]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.696808510...</td>\n      <td>0.456545</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G08</td>\n      <td>(6856, 25)</td>\n      <td>(1288, 25)</td>\n      <td>{0.0: 5484, 1.0: 1372}</td>\n      <td>{1.0: 1203, 0.0: 85}</td>\n      <td>0.445136</td>\n      <td>0.443155</td>\n      <td>0.445136</td>\n      <td>0.445136</td>\n      <td>[[ 62  21]\\n [692 510]]</td>\n      <td>{'0': {'precision': 0.08222811671087533, 'reca...</td>\n      <td>1.289882</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G04</td>\n      <td>(7832, 25)</td>\n      <td>(312, 25)</td>\n      <td>{0.0: 5492, 1.0: 2340}</td>\n      <td>{1.0: 235, 0.0: 77}</td>\n      <td>0.427184</td>\n      <td>0.421580</td>\n      <td>0.427184</td>\n      <td>0.427184</td>\n      <td>[[  8  66]\\n [111 124]]</td>\n      <td>{'0': {'precision': 0.06722689075630252, 'reca...</td>\n      <td>1.352790</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_900 = df.loc[(df['window'] == 900)]\n",
    "df_900.sort_values(by=['f1_score'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistical Analysis of LOOCV results with window size of 900"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       window  step   accuracy   f1_score  precision     recall       loss\ncount    16.0  16.0  16.000000  16.000000  16.000000  16.000000  16.000000\nmean    900.0  90.0   0.830304   0.832466   0.830304   0.830304   0.400475\nstd       0.0   0.0   0.169596   0.170803   0.169596   0.169596   0.395440\nmin     900.0  90.0   0.427184   0.421580   0.427184   0.427184   0.018532\n25%     900.0  90.0   0.814650   0.837187   0.814650   0.814650   0.175435\n50%     900.0  90.0   0.880878   0.886803   0.880878   0.880878   0.301158\n75%     900.0  90.0   0.923354   0.925461   0.923354   0.923354   0.422999\nmax     900.0  90.0   0.989967   0.990625   0.989967   0.989967   1.352790",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window</th>\n      <th>step</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>16.000000</td>\n      <td>16.000000</td>\n      <td>16.000000</td>\n      <td>16.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.830304</td>\n      <td>0.832466</td>\n      <td>0.830304</td>\n      <td>0.830304</td>\n      <td>0.400475</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.169596</td>\n      <td>0.170803</td>\n      <td>0.169596</td>\n      <td>0.169596</td>\n      <td>0.395440</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.427184</td>\n      <td>0.421580</td>\n      <td>0.427184</td>\n      <td>0.427184</td>\n      <td>0.018532</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.814650</td>\n      <td>0.837187</td>\n      <td>0.814650</td>\n      <td>0.814650</td>\n      <td>0.175435</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.880878</td>\n      <td>0.886803</td>\n      <td>0.880878</td>\n      <td>0.880878</td>\n      <td>0.301158</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.923354</td>\n      <td>0.925461</td>\n      <td>0.923354</td>\n      <td>0.923354</td>\n      <td>0.422999</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>900.0</td>\n      <td>90.0</td>\n      <td>0.989967</td>\n      <td>0.990625</td>\n      <td>0.989967</td>\n      <td>0.989967</td>\n      <td>1.352790</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_900.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ====== Results Analysis Using Weighted-Average ============="
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "df = pd.read_csv('windows_results.csv', sep=',')\n",
    "df.clf_report = df.clf_report.apply(lambda x: ast.literal_eval(x))\n",
    "df['weighted_avg'] = [d.get('weighted avg') for d in df.clf_report]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_results = df.copy()\n",
    "df_results = df_results.drop(['precision', 'recall', 'f1_score',], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_results['precision'] = [d.get('precision') for d in df_results.weighted_avg]\n",
    "df_results['recall'] = [d.get('recall') for d in df_results.weighted_avg]\n",
    "df_results['f1-score'] = [d.get('f1-score') for d in df_results.weighted_avg]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "             f1-score  precision    recall      loss\nwindow step                                         \n200    20    0.777505   0.846262  0.772391  0.531842\n300    30    0.794342   0.896134  0.773462  0.497387\n400    40    0.833098   0.905604  0.818742  0.478788\n500    50    0.819449   0.906750  0.782341  0.466432\n600    60    0.842760   0.915920  0.803789  0.421888\n700    70    0.840230   0.918093  0.805657  0.412159\n800    80    0.844300   0.921163  0.816482  0.396200\n900    90    0.861992   0.925849  0.830304  0.400475",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>f1-score</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>loss</th>\n    </tr>\n    <tr>\n      <th>window</th>\n      <th>step</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>200</th>\n      <th>20</th>\n      <td>0.777505</td>\n      <td>0.846262</td>\n      <td>0.772391</td>\n      <td>0.531842</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <th>30</th>\n      <td>0.794342</td>\n      <td>0.896134</td>\n      <td>0.773462</td>\n      <td>0.497387</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <th>40</th>\n      <td>0.833098</td>\n      <td>0.905604</td>\n      <td>0.818742</td>\n      <td>0.478788</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <th>50</th>\n      <td>0.819449</td>\n      <td>0.906750</td>\n      <td>0.782341</td>\n      <td>0.466432</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <th>60</th>\n      <td>0.842760</td>\n      <td>0.915920</td>\n      <td>0.803789</td>\n      <td>0.421888</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <th>70</th>\n      <td>0.840230</td>\n      <td>0.918093</td>\n      <td>0.805657</td>\n      <td>0.412159</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <th>80</th>\n      <td>0.844300</td>\n      <td>0.921163</td>\n      <td>0.816482</td>\n      <td>0.396200</td>\n    </tr>\n    <tr>\n      <th>900</th>\n      <th>90</th>\n      <td>0.861992</td>\n      <td>0.925849</td>\n      <td>0.830304</td>\n      <td>0.400475</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(['window', 'step'])[['f1-score', 'precision' , 'recall', 'loss']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     window  step test_patient train_shape  test_shape  \\\n119     900    90         P231  (7842, 25)   (302, 25)   \n127     900    90         P940  (7205, 25)   (939, 25)   \n117     900    90          G09  (7901, 25)   (243, 25)   \n120     900    90         P351  (7024, 25)  (1120, 25)   \n123     900    90         P623  (7935, 25)   (209, 25)   \n126     900    90         P876  (7895, 25)   (249, 25)   \n114     900    90          G06  (7956, 25)   (188, 25)   \n124     900    90         P645  (7811, 25)   (333, 25)   \n125     900    90         P812  (6674, 25)  (1470, 25)   \n122     900    90         P551  (7758, 25)   (386, 25)   \n121     900    90         P379  (7729, 25)   (415, 25)   \n115     900    90          G07  (7796, 25)   (348, 25)   \n118     900    90          G11  (7993, 25)   (151, 25)   \n113     900    90          G05  (7953, 25)   (191, 25)   \n116     900    90          G08  (6856, 25)  (1288, 25)   \n112     900    90          G04  (7832, 25)   (312, 25)   \n\n          train_lable_count       test_label_count  accuracy  \\\n119  {0.0: 5267, 1.0: 2575}             {0.0: 302}  0.989967   \n127  {0.0: 4630, 1.0: 2575}             {0.0: 939}  0.982906   \n117  {0.0: 5326, 1.0: 2575}             {0.0: 243}  0.954167   \n120  {0.0: 4449, 1.0: 2575}            {0.0: 1120}  0.919427   \n123  {0.0: 5360, 1.0: 2575}             {0.0: 209}  0.883495   \n126  {0.0: 5320, 1.0: 2575}             {0.0: 249}  0.878049   \n114  {0.0: 5449, 1.0: 2507}    {0.0: 120, 1.0: 68}  0.935135   \n124  {0.0: 5236, 1.0: 2575}             {0.0: 333}  0.818182   \n125  {0.0: 4363, 1.0: 2311}  {0.0: 1206, 1.0: 264}  0.892297   \n122  {0.0: 5523, 1.0: 2235}    {1.0: 340, 0.0: 46}  0.906005   \n121  {0.0: 5297, 1.0: 2432}   {0.0: 272, 1.0: 143}  0.873786   \n115  {0.0: 5514, 1.0: 2282}    {1.0: 293, 0.0: 55}  0.878261   \n118  {0.0: 5447, 1.0: 2546}    {0.0: 122, 1.0: 29}  0.804054   \n113  {0.0: 5378, 1.0: 2575}             {0.0: 191}  0.696809   \n116  {0.0: 5484, 1.0: 1372}   {1.0: 1203, 0.0: 85}  0.445136   \n112  {0.0: 5492, 1.0: 2340}    {1.0: 235, 0.0: 77}  0.427184   \n\n                     conf_matrix  \\\n119      [[296   3]\\n [  0   0]]   \n127      [[920  16]\\n [  0   0]]   \n117      [[229  11]\\n [  0   0]]   \n120  [[1027   90]\\n [   0    0]]   \n123      [[182  24]\\n [  0   0]]   \n126      [[216  30]\\n [  0   0]]   \n114      [[113   4]\\n [  8  60]]   \n124      [[270  60]\\n [  0   0]]   \n125  [[1090  113]\\n [  45  219]]   \n122      [[  9  35]\\n [  1 338]]   \n121      [[249  20]\\n [ 32 111]]   \n115      [[ 12  40]\\n [  2 291]]   \n118          [[90 29]\\n [ 0 29]]   \n113      [[131  57]\\n [  0   0]]   \n116      [[ 62  21]\\n [692 510]]   \n112      [[  8  66]\\n [111 124]]   \n\n                                            clf_report      loss  \\\n119  {'0': {'precision': 1.0, 'recall': 0.989966555...  0.018532   \n127  {'0': {'precision': 1.0, 'recall': 0.982905982...  0.032510   \n117  {'0': {'precision': 1.0, 'recall': 0.954166666...  0.079220   \n120  {'0': {'precision': 1.0, 'recall': 0.919427036...  0.129470   \n123  {'0': {'precision': 1.0, 'recall': 0.883495145...  0.190756   \n126  {'0': {'precision': 1.0, 'recall': 0.878048780...  0.199090   \n114  {'0': {'precision': 0.9338842975206612, 'recal...  0.283994   \n124  {'0': {'precision': 1.0, 'recall': 0.818181818...  0.318321   \n125  {'0': {'precision': 0.960352422907489, 'recall...  0.271780   \n122  {'0': {'precision': 0.9, 'recall': 0.204545454...  0.371937   \n121  {'0': {'precision': 0.8861209964412812, 'recal...  0.649162   \n115  {'0': {'precision': 0.8571428571428571, 'recal...  0.411816   \n118  {'0': {'precision': 1.0, 'recall': 0.756302521...  0.351790   \n113  {'0': {'precision': 1.0, 'recall': 0.696808510...  0.456545   \n116  {'0': {'precision': 0.08222811671087533, 'reca...  1.289882   \n112  {'0': {'precision': 0.06722689075630252, 'reca...  1.352790   \n\n                                          weighted_avg  precision    recall  \\\n119  {'precision': 1.0, 'recall': 0.989966555183946...   1.000000  0.989967   \n127  {'precision': 1.0, 'recall': 0.982905982905982...   1.000000  0.982906   \n117  {'precision': 1.0, 'recall': 0.954166666666666...   1.000000  0.954167   \n120  {'precision': 1.0, 'recall': 0.919427036705461...   1.000000  0.919427   \n123  {'precision': 1.0, 'recall': 0.883495145631068...   1.000000  0.883495   \n126  {'precision': 1.0, 'recall': 0.878048780487804...   1.000000  0.878049   \n114  {'precision': 0.9352133124860397, 'recall': 0....   0.935213  0.935135   \n124  {'precision': 1.0, 'recall': 0.818181818181818...   1.000000  0.818182   \n125  {'precision': 0.9062362256789109, 'recall': 0....   0.906236  0.892297   \n122  {'precision': 0.9054578290482225, 'recall': 0....   0.905458  0.906005   \n121  {'precision': 0.8726565217815591, 'recall': 0....   0.872657  0.873786   \n115  {'precision': 0.8758364451783603, 'recall': 0....   0.875836  0.878261   \n118  {'precision': 0.902027027027027, 'recall': 0.8...   0.902027  0.804054   \n113  {'precision': 1.0, 'recall': 0.696808510638297...   1.000000  0.696809   \n116  {'precision': 0.903726233870164, 'recall': 0.4...   0.903726  0.445136   \n112  {'precision': 0.5124375759501553, 'recall': 0....   0.512438  0.427184   \n\n     f1-score  \n119  0.994958  \n127  0.991379  \n117  0.976546  \n120  0.958022  \n123  0.938144  \n126  0.935065  \n114  0.934697  \n124  0.900000  \n125  0.896875  \n122  0.878659  \n121  0.872399  \n115  0.846922  \n118  0.823117  \n113  0.821317  \n116  0.560127  \n112  0.463638  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window</th>\n      <th>step</th>\n      <th>test_patient</th>\n      <th>train_shape</th>\n      <th>test_shape</th>\n      <th>train_lable_count</th>\n      <th>test_label_count</th>\n      <th>accuracy</th>\n      <th>conf_matrix</th>\n      <th>clf_report</th>\n      <th>loss</th>\n      <th>weighted_avg</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>119</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P231</td>\n      <td>(7842, 25)</td>\n      <td>(302, 25)</td>\n      <td>{0.0: 5267, 1.0: 2575}</td>\n      <td>{0.0: 302}</td>\n      <td>0.989967</td>\n      <td>[[296   3]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.989966555...</td>\n      <td>0.018532</td>\n      <td>{'precision': 1.0, 'recall': 0.989966555183946...</td>\n      <td>1.000000</td>\n      <td>0.989967</td>\n      <td>0.994958</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P940</td>\n      <td>(7205, 25)</td>\n      <td>(939, 25)</td>\n      <td>{0.0: 4630, 1.0: 2575}</td>\n      <td>{0.0: 939}</td>\n      <td>0.982906</td>\n      <td>[[920  16]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.982905982...</td>\n      <td>0.032510</td>\n      <td>{'precision': 1.0, 'recall': 0.982905982905982...</td>\n      <td>1.000000</td>\n      <td>0.982906</td>\n      <td>0.991379</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G09</td>\n      <td>(7901, 25)</td>\n      <td>(243, 25)</td>\n      <td>{0.0: 5326, 1.0: 2575}</td>\n      <td>{0.0: 243}</td>\n      <td>0.954167</td>\n      <td>[[229  11]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.954166666...</td>\n      <td>0.079220</td>\n      <td>{'precision': 1.0, 'recall': 0.954166666666666...</td>\n      <td>1.000000</td>\n      <td>0.954167</td>\n      <td>0.976546</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P351</td>\n      <td>(7024, 25)</td>\n      <td>(1120, 25)</td>\n      <td>{0.0: 4449, 1.0: 2575}</td>\n      <td>{0.0: 1120}</td>\n      <td>0.919427</td>\n      <td>[[1027   90]\\n [   0    0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.919427036...</td>\n      <td>0.129470</td>\n      <td>{'precision': 1.0, 'recall': 0.919427036705461...</td>\n      <td>1.000000</td>\n      <td>0.919427</td>\n      <td>0.958022</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P623</td>\n      <td>(7935, 25)</td>\n      <td>(209, 25)</td>\n      <td>{0.0: 5360, 1.0: 2575}</td>\n      <td>{0.0: 209}</td>\n      <td>0.883495</td>\n      <td>[[182  24]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.883495145...</td>\n      <td>0.190756</td>\n      <td>{'precision': 1.0, 'recall': 0.883495145631068...</td>\n      <td>1.000000</td>\n      <td>0.883495</td>\n      <td>0.938144</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P876</td>\n      <td>(7895, 25)</td>\n      <td>(249, 25)</td>\n      <td>{0.0: 5320, 1.0: 2575}</td>\n      <td>{0.0: 249}</td>\n      <td>0.878049</td>\n      <td>[[216  30]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.878048780...</td>\n      <td>0.199090</td>\n      <td>{'precision': 1.0, 'recall': 0.878048780487804...</td>\n      <td>1.000000</td>\n      <td>0.878049</td>\n      <td>0.935065</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G06</td>\n      <td>(7956, 25)</td>\n      <td>(188, 25)</td>\n      <td>{0.0: 5449, 1.0: 2507}</td>\n      <td>{0.0: 120, 1.0: 68}</td>\n      <td>0.935135</td>\n      <td>[[113   4]\\n [  8  60]]</td>\n      <td>{'0': {'precision': 0.9338842975206612, 'recal...</td>\n      <td>0.283994</td>\n      <td>{'precision': 0.9352133124860397, 'recall': 0....</td>\n      <td>0.935213</td>\n      <td>0.935135</td>\n      <td>0.934697</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P645</td>\n      <td>(7811, 25)</td>\n      <td>(333, 25)</td>\n      <td>{0.0: 5236, 1.0: 2575}</td>\n      <td>{0.0: 333}</td>\n      <td>0.818182</td>\n      <td>[[270  60]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.818181818...</td>\n      <td>0.318321</td>\n      <td>{'precision': 1.0, 'recall': 0.818181818181818...</td>\n      <td>1.000000</td>\n      <td>0.818182</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P812</td>\n      <td>(6674, 25)</td>\n      <td>(1470, 25)</td>\n      <td>{0.0: 4363, 1.0: 2311}</td>\n      <td>{0.0: 1206, 1.0: 264}</td>\n      <td>0.892297</td>\n      <td>[[1090  113]\\n [  45  219]]</td>\n      <td>{'0': {'precision': 0.960352422907489, 'recall...</td>\n      <td>0.271780</td>\n      <td>{'precision': 0.9062362256789109, 'recall': 0....</td>\n      <td>0.906236</td>\n      <td>0.892297</td>\n      <td>0.896875</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P551</td>\n      <td>(7758, 25)</td>\n      <td>(386, 25)</td>\n      <td>{0.0: 5523, 1.0: 2235}</td>\n      <td>{1.0: 340, 0.0: 46}</td>\n      <td>0.906005</td>\n      <td>[[  9  35]\\n [  1 338]]</td>\n      <td>{'0': {'precision': 0.9, 'recall': 0.204545454...</td>\n      <td>0.371937</td>\n      <td>{'precision': 0.9054578290482225, 'recall': 0....</td>\n      <td>0.905458</td>\n      <td>0.906005</td>\n      <td>0.878659</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>900</td>\n      <td>90</td>\n      <td>P379</td>\n      <td>(7729, 25)</td>\n      <td>(415, 25)</td>\n      <td>{0.0: 5297, 1.0: 2432}</td>\n      <td>{0.0: 272, 1.0: 143}</td>\n      <td>0.873786</td>\n      <td>[[249  20]\\n [ 32 111]]</td>\n      <td>{'0': {'precision': 0.8861209964412812, 'recal...</td>\n      <td>0.649162</td>\n      <td>{'precision': 0.8726565217815591, 'recall': 0....</td>\n      <td>0.872657</td>\n      <td>0.873786</td>\n      <td>0.872399</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G07</td>\n      <td>(7796, 25)</td>\n      <td>(348, 25)</td>\n      <td>{0.0: 5514, 1.0: 2282}</td>\n      <td>{1.0: 293, 0.0: 55}</td>\n      <td>0.878261</td>\n      <td>[[ 12  40]\\n [  2 291]]</td>\n      <td>{'0': {'precision': 0.8571428571428571, 'recal...</td>\n      <td>0.411816</td>\n      <td>{'precision': 0.8758364451783603, 'recall': 0....</td>\n      <td>0.875836</td>\n      <td>0.878261</td>\n      <td>0.846922</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G11</td>\n      <td>(7993, 25)</td>\n      <td>(151, 25)</td>\n      <td>{0.0: 5447, 1.0: 2546}</td>\n      <td>{0.0: 122, 1.0: 29}</td>\n      <td>0.804054</td>\n      <td>[[90 29]\\n [ 0 29]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.756302521...</td>\n      <td>0.351790</td>\n      <td>{'precision': 0.902027027027027, 'recall': 0.8...</td>\n      <td>0.902027</td>\n      <td>0.804054</td>\n      <td>0.823117</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G05</td>\n      <td>(7953, 25)</td>\n      <td>(191, 25)</td>\n      <td>{0.0: 5378, 1.0: 2575}</td>\n      <td>{0.0: 191}</td>\n      <td>0.696809</td>\n      <td>[[131  57]\\n [  0   0]]</td>\n      <td>{'0': {'precision': 1.0, 'recall': 0.696808510...</td>\n      <td>0.456545</td>\n      <td>{'precision': 1.0, 'recall': 0.696808510638297...</td>\n      <td>1.000000</td>\n      <td>0.696809</td>\n      <td>0.821317</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G08</td>\n      <td>(6856, 25)</td>\n      <td>(1288, 25)</td>\n      <td>{0.0: 5484, 1.0: 1372}</td>\n      <td>{1.0: 1203, 0.0: 85}</td>\n      <td>0.445136</td>\n      <td>[[ 62  21]\\n [692 510]]</td>\n      <td>{'0': {'precision': 0.08222811671087533, 'reca...</td>\n      <td>1.289882</td>\n      <td>{'precision': 0.903726233870164, 'recall': 0.4...</td>\n      <td>0.903726</td>\n      <td>0.445136</td>\n      <td>0.560127</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>900</td>\n      <td>90</td>\n      <td>G04</td>\n      <td>(7832, 25)</td>\n      <td>(312, 25)</td>\n      <td>{0.0: 5492, 1.0: 2340}</td>\n      <td>{1.0: 235, 0.0: 77}</td>\n      <td>0.427184</td>\n      <td>[[  8  66]\\n [111 124]]</td>\n      <td>{'0': {'precision': 0.06722689075630252, 'reca...</td>\n      <td>1.352790</td>\n      <td>{'precision': 0.5124375759501553, 'recall': 0....</td>\n      <td>0.512438</td>\n      <td>0.427184</td>\n      <td>0.463638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_900 = df_results.loc[(df['window'] == 900)]\n",
    "df_results_900.sort_values(by=['f1-score'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}